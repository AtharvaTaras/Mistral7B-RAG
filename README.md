# Mistral7B-RAG
Local Implementation of RAG (Retrieval Augmented Generation) with Mistral 7B Chat Model (4bit Sharded)

![Screenshot (1623)](https://github.com/AtharvaTaras/Mistral7B-RAG/assets/78966432/b99cd6ee-7ffd-46ce-be0c-5958fe0aceab)

### Installation
```
conda create -n my_env python=3.10
conda activate my_env
pip install -r requiremnts.txt
```  
  
[Download the model](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf)  

### Additional Requirements   
You may need these in case pip fails to build llama-cpp-python  
[Visual Studio Community](https://visualstudio.microsoft.com/downloads/)  
Install devleopment kit for C++ and Python  
[Cmake](https://cmake.org/download/)  
[Nvidia Cuda Toolkit](https://developer.nvidia.com/cuda-toolkit)  

